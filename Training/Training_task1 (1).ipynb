{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7042efd3-eebf-470e-b411-11e9beed088b",
   "metadata": {},
   "source": [
    "# Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d165895-eabb-4e2b-b12c-016d4635d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import random\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "import logging\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f01f96-3d7d-4b40-9668-e1ae433e71eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "InputSPI=pd.DataFrame()\n",
    "for item in range(4):\n",
    "    InputSPI=pd.concat([InputSPI,pd.read_csv('data-challenge-phme/data/SPI_training_'+str(item)+'.csv.zip')])\n",
    "    \n",
    "#InputSPI=cleaning_SPI(InputSPI)\n",
    "\n",
    "InputAOI=pd.read_csv('data-challenge-phme/data/AOI_training.csv.zip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eea68f-acd8-48ff-9657-daf5e33bec3e",
   "metadata": {},
   "source": [
    "# Data Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi=InputSPI.copy()\n",
    "aoi=InputAOI.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demonstrated-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi[\"ComponentID2\"]=spi[\"ComponentID\"]\n",
    "spi[\"FigureID2\"]=spi[\"FigureID\"]\n",
    "\n",
    "aoi['PinNumber']=aoi['PinNumber'].astype('Int64').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amateur-clinton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_training=spi.merge(aoi,on=['PanelID','FigureID','ComponentID','PinNumber'],how=\"left\")\n",
    "spi_training=spi_training.drop_duplicates(subset=['PanelID','FigureID','ComponentID','PinNumber'])\n",
    "Num_features_to_cat=['Volume(%)','Area(%)', 'OffsetX(%)','OffsetY(%)']\n",
    "Num_features=['Shape(um)',\n",
    "       'PosX(mm)', 'PosY(mm)','SizeX', 'SizeY']\n",
    "\n",
    "Cat_features=['FigureID','PinNumber','PadID', 'PadType','Result']\n",
    "\n",
    "spi_training['Target']=spi_training['MachineID'].isna()\n",
    "spi_training=spi_training.dropna(subset=Num_features)\n",
    "\n",
    "for feat in Num_features:\n",
    "    spi_training[feat]=spi_training[feat].astype('float')\n",
    "    \n",
    "spi_training[\"ComponentID2\"]=spi_training[\"ComponentID\"].astype('category').cat.codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66656ace-72b7-4815-a76a-425fb943da52",
   "metadata": {},
   "source": [
    "# Training set Creation + Encoding with Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63af6a3-8f34-4fd9-9f2b-940e90b117ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df=spi_trainin.reset_index(drop=True)\n",
    "#Train_df=Train_df.loc[Train_df.ComponentID!=\"BC1\"]\n",
    "#Test_df=Test_df.loc[Test_df.ComponentID!=\"BC1\"]\n",
    "\n",
    "X_train=Train_df\n",
    "y_train=Train_df['Target']\n",
    "\n",
    "encoder=ce.CatBoostEncoder(a=0.3)\n",
    "\n",
    "AE_val=encoder.fit_transform(Train_df[\"ComponentID2\"].copy(),y_train)\n",
    "AE_val.columns=[x+\"_encoded\" for x in AE_val.columns.tolist()]\n",
    "Train_df=pd.concat([Train_df,AE_val],axis=1)\n",
    "features_x=[x for x in Train_df.columns if \"_encoded\" in x]\n",
    "joblib.dump(encoder,\"Cat_boost_step1\")\n",
    "\n",
    "\n",
    "X_train_final=Train_df[features_x].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df104a5f-5dde-42cc-9c23-968b43e51c31",
   "metadata": {},
   "source": [
    "# Optuna Hyperparametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16b8b4-195c-4095-b022-ca7d89b24579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=np.sum(y_train==0)/np.sum(y_train==1)\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial: Trial,X,y) -> float:\n",
    "    \n",
    "    joblib.dump(study, 'study.pkl')\n",
    "\n",
    "    param = {\n",
    "        'objective': trial.suggest_categorical('objective',['binary:logistic']), \n",
    "        'tree_method': trial.suggest_categorical('tree_method',['exact']),  # 'gpu_hist','hist'\n",
    "        'lambda': trial.suggest_loguniform('lambda',1e-3,10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha',1e-3,10.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.3,1.0),\n",
    "        #'subsample': trial.suggest_uniform('subsample', 0.4, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001,0.1),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [30,40,50,70,100,150,200]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3,5,7,9,11,13,15,17,20]),\n",
    "        #'random_state': trial.suggest_categorical('random_state', [24,48,2020]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1,300),\n",
    "        'nthread' : -1,\n",
    "        #0'feval': trial.suggest_categorical('feval',[f1_eval]),\n",
    "        #'scale_pos_weight' : trial.suggest_categorical('scale_pos_weight', [ratio])\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "    model = xgboost.XGBClassifier(**param,feval=f1_eval)\n",
    "    \n",
    "    return cross_val_score(model, X_train_final, y_train, cv=5,scoring=make_scorer(f1_score, pos_label=0)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d12564-9158-482b-80b4-777824b45db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def f1_eval(y_pred, y_true):\n",
    "    #y_true = dtrain.get_label()\n",
    "    err = f1_score(y_true,y_pred,pos_label=0)\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5478b-7040-4a4b-8217-8cec0390031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "#study = optuna.create_study(direction='maximize', storage=\"sqlite:///xgb_optuna_home_credit.db\", study_name=\"optuna_xgb_output_8\")\n",
    "study.optimize(lambda trial : objective(trial,X_train_final,y_train),n_trials= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45a5b8-bdef-48b9-8b72-7bcd400ce883",
   "metadata": {},
   "source": [
    "# Best trial model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286e76d-2785-47ed-afaf-2674465a2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_trial = study.best_trial.params\n",
    "model = xgboost.XGBClassifier(**Best_trial)\n",
    "model.fit(X_train_final,y_train)\n",
    "confusion_matrix(y_train, model.predict(X_train_final),labels=[0,1])\n",
    "cross_val_score(model, X_train_final, y_train, cv=5,scoring=make_scorer(f1_score, pos_label=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9840782-85c6-4a2b-892a-e7091e4a4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_step1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "list_panel_id=InputAOI.PanelID.unique().tolist()\n",
    "\n",
    "def cross_validation_panel_id_creation(list_panel_id,n_fold=5):\n",
    "    Fold_list=[]\n",
    "    random.shuffle(list_panel_id)\n",
    "    #list_panel_id=joblib.load(\"list_panel_id\")\n",
    "    len_fold=(len(list_panel_id))//n_fold\n",
    "    for fold in range(n_fold):\n",
    "        Fold_list.append(list_panel_id[fold*len_fold:(fold+1)*len_fold])\n",
    "    return(Fold_list)\n",
    "Fold_list=cross_validation_panel_id_creation(list_panel_id)\n",
    "#Final_df=Final_df.loc[Final_df['ComponentID2']!=\"BC1\"]\n",
    "f1_score_list=[]\n",
    "list_confusion_matrix=[]\n",
    "for Test_fold_indice in range(1):\n",
    "    print(Test_fold_indice)\n",
    "    Train_indice=[]\n",
    "    count_indice_fit_pin_training=0\n",
    "    for indices in range(len(Fold_list)):\n",
    "        if indices!=Test_fold_indice:\n",
    "            Train_indice=Train_indice+Fold_list[indices]\n",
    "        else:\n",
    "            Test_indices=Fold_list[indices]\n",
    "            #Train_indice=Train_indice+Fold_list[indices]\n",
    "\n",
    "    Train_df=spi_training.loc[spi_training[\"PanelID\"].isin(Train_indice)].reset_index(drop=True)\n",
    "    #Train_df=Train_df.loc[Train_df.ComponentID!=\"BC1\"]\n",
    "    Test_df=spi_training.loc[spi_training[\"PanelID\"].isin(Test_indices)].reset_index(drop=True)\n",
    "    #Test_df=Test_df.loc[Test_df.ComponentID!=\"BC1\"]\n",
    "\n",
    "    X_train=Train_df\n",
    "    X_val=Test_df\n",
    "    y_train=Train_df['Target']\n",
    "    y_val=Test_df['Target']\n",
    "    y_train=Train_df['Target']\n",
    "    y_train=Train_df['Target']\n",
    "    y_val=Test_df['Target']\n",
    "    encoder=ce.CatBoostEncoder(a=0.3)\n",
    "\n",
    "    AE_val=encoder.fit_transform(Train_df[\"ComponentID2\"].copy(),y_train)\n",
    "    AE_val.columns=[x+\"_encoded\" for x in AE_val.columns.tolist()]\n",
    "    Train_df=pd.concat([Train_df,AE_val],axis=1)\n",
    "    features_x=[x for x in Train_df.columns if \"_encoded\" in x]\n",
    "    joblib.dump(encoder,\"Cat_boost_step1\")\n",
    "\n",
    "    AE_val=encoder.transform(Test_df[\"ComponentID2\"].copy())\n",
    "    AE_val.columns=[x+\"_encoded\" for x in AE_val.columns.tolist()]\n",
    "    Test_df=pd.concat([Test_df,AE_val],axis=1)\n",
    "\n",
    "    features_x=[\"ComponentID2_encoded\"]+Num_features_to_cat+Num_features\n",
    "    \n",
    "    X_train_final=Train_df[features_x].to_numpy()\n",
    "    X_val_final=Test_df[features_x].to_numpy()\n",
    "    \n",
    "    xgb_cl =model\n",
    "    xgb_cl.fit(X_train_final, y_train)\n",
    "\n",
    "\n",
    "    res_train=xgb_cl.predict(X_train_final)\n",
    "    res_test=xgb_cl.predict(X_val_final)\n",
    "\n",
    "    X_train['Pred']=res_train\n",
    "    X_val['Pred']=res_test\n",
    "   \n",
    "    \n",
    "    y_train=X_train.groupby([\"PanelID\",\"FigureID\",\"ComponentID\"])['Target'].min()\n",
    "    y_val=X_val.groupby([\"PanelID\",\"FigureID\",\"ComponentID\"])['Target'].min()\n",
    "\n",
    "\n",
    "    res_train=X_train.groupby([\"PanelID\",\"FigureID\",\"ComponentID\"])['Pred'].min()\n",
    "    res_test=X_val.groupby([\"PanelID\",\"FigureID\",\"ComponentID\"])['Pred'].min()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(confusion_matrix(y_train, res_train,labels=[0,1]))\n",
    "    print(confusion_matrix(y_val,res_test,labels=[0,1]))\n",
    "\n",
    "    print(f1_score(y_train, res_train,pos_label=0))\n",
    "    print(f1_score(y_val, res_test,pos_label=0))\n",
    "    f1_score_list.append(f1_score(y_val, res_test,pos_label=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
